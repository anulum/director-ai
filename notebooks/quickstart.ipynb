{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Director-AI — Protect any LLM in 10 lines\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/anulum/director-ai/blob/main/notebooks/quickstart.ipynb)\n",
    "[![PyPI](https://img.shields.io/pypi/v/director-ai.svg)](https://pypi.org/project/director-ai/)\n",
    "\n",
    "**Director-AI** is a real-time LLM hallucination guardrail. It scores every LLM output\n",
    "for coherence against your own knowledge base — and can halt generation mid-stream if\n",
    "coherence drops below threshold.\n",
    "\n",
    "This notebook covers:\n",
    "1. Install + basic scoring\n",
    "2. Guard an LLM (no API key needed)\n",
    "3. Streaming halt demo\n",
    "4. Domain presets\n",
    "5. Full agent pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q director-ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Score a Response\n",
    "\n",
    "The `CoherenceScorer` computes a dual-entropy score: logical divergence (contradiction)\n",
    "and factual divergence (deviation from your facts). Both must pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from director_ai.core import CoherenceScorer, GroundTruthStore\n",
    "\n",
    "store = GroundTruthStore()\n",
    "store.add(\"capital\", \"Paris is the capital of France.\")\n",
    "store.add(\"sky color\", \"The sky is blue due to Rayleigh scattering.\")\n",
    "\n",
    "scorer = CoherenceScorer(threshold=0.6, ground_truth_store=store, use_nli=False)\n",
    "\n",
    "tests = [\n",
    "    (\"What is the capital of France?\", \"The capital of France is Paris.\"),\n",
    "    (\"What is the capital of France?\", \"The capital of France is Berlin.\"),\n",
    "    (\"What color is the sky?\", \"The sky is blue.\"),\n",
    "    (\"What color is the sky?\", \"The sky is green, obviously.\"),\n",
    "]\n",
    "\n",
    "for prompt, llm_output in tests:\n",
    "    approved, score = scorer.review(prompt, llm_output)\n",
    "    status = \"PASS\" if approved else \"BLOCKED\"\n",
    "    print(f\"[{status}] {llm_output}\")\n",
    "    print(f\"  coherence={score.score:.3f}  h_logical={score.h_logical:.2f}  h_factual={score.h_factual:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Guard an LLM\n",
    "\n",
    "The `guard()` wrapper intercepts any OpenAI-compatible client. Here we use `MockGenerator` so no API key is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from director_ai import CoherenceAgent\n",
    "\n",
    "agent = CoherenceAgent()  # MockGenerator — no API key required\n",
    "result = agent.process(\"What color is the sky?\")\n",
    "\n",
    "print(f\"Output:  {result.output}\")\n",
    "print(f\"Halted:  {result.halted}\")\n",
    "if result.coherence:\n",
    "    print(f\"Score:   {result.coherence.score:.3f}\")\n",
    "    print(f\"Approved: {result.coherence.approved}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Streaming Halt\n",
    "\n",
    "The `StreamingKernel` monitors coherence **token-by-token** and halts generation\n",
    "the moment it degrades. Three halt mechanisms:\n",
    "- **Hard limit** — single token below absolute floor\n",
    "- **Sliding window** — rolling average drops\n",
    "- **Downward trend** — coherence decay over N tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from director_ai.core import StreamingKernel\n",
    "\n",
    "kernel = StreamingKernel(\n",
    "    hard_limit=0.35,\n",
    "    window_size=5,\n",
    "    window_threshold=0.45,\n",
    ")\n",
    "\n",
    "# Synthetic tokens: starts accurate, drifts into hallucination\n",
    "tokens = [\n",
    "    \"Water\", \" boils\", \" at\", \" 100\", \" C.\",\n",
    "    \" But\", \" actually\", \" the\", \" real\",\n",
    "    \" temperature\", \" is\", \" negative\", \" forty\", \".\",\n",
    "]\n",
    "scores = [\n",
    "    0.92, 0.90, 0.91, 0.89, 0.88,\n",
    "    0.72, 0.55, 0.40, 0.30, 0.15, 0.10, 0.08, 0.05, 0.03,\n",
    "]\n",
    "\n",
    "idx = 0\n",
    "def coherence_cb(tok):\n",
    "    global idx\n",
    "    s = scores[min(idx, len(scores) - 1)]\n",
    "    idx += 1\n",
    "    return s\n",
    "\n",
    "session = kernel.stream_tokens(iter(tokens), coherence_cb)\n",
    "\n",
    "for ev in session.events:\n",
    "    marker = \" <<<HALT\" if ev.halted else \"\"\n",
    "    print(f\"  [{ev.index:2d}] {ev.coherence:.3f}  {ev.token!r}{marker}\")\n",
    "\n",
    "print(f\"\\nHalted: {session.halted}\")\n",
    "if session.halted:\n",
    "    print(f\"Reason: {session.halt_reason}\")\n",
    "print(f\"Tokens: {session.token_count}/{len(tokens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Domain Presets\n",
    "\n",
    "Director-AI ships 8 domain profiles with tuned thresholds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from director_ai.core.config import DirectorConfig\n",
    "\n",
    "profiles = [\"fast\", \"thorough\", \"research\", \"medical\", \"finance\", \"legal\", \"creative\", \"customer_support\"]\n",
    "\n",
    "print(f\"{'Profile':<18} {'Threshold':>9} {'Hard Limit':>10} {'NLI':>5} {'w_logic':>7} {'w_fact':>7}\")\n",
    "print(\"-\" * 60)\n",
    "for name in profiles:\n",
    "    cfg = DirectorConfig.from_profile(name)\n",
    "    print(\n",
    "        f\"{name:<18} {cfg.coherence_threshold:>9.2f} {cfg.hard_limit:>10.2f}\"\n",
    "        f\" {str(cfg.use_nli):>5} {cfg.w_logic:>7.1f} {cfg.w_fact:>7.1f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- [Full docs](https://anulum.github.io/director-ai/) — scoring, streaming, deployment\n",
    "- [GitHub](https://github.com/anulum/director-ai) — source, issues, contributing\n",
    "- [PyPI](https://pypi.org/project/director-ai/) — `pip install director-ai[nli]` for NLI scoring\n",
    "- [HF Spaces demo](https://huggingface.co/spaces/anulum/director-ai-guardrail) — try it in your browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!director-ai version"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
