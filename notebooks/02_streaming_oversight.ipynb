{
 "cells": [
  {"cell_type": "markdown", "metadata": {}, "source": ["# 02 — Streaming Token-by-Token Oversight\n", "\n", "Demonstrates `StreamingKernel` and `AsyncStreamingKernel` for\n", "real-time token-level coherence monitoring."]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from director_ai.core.streaming import StreamingKernel, TokenEvent"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Sync Streaming\n", "Process a token stream with 3 halt mechanisms."]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["kernel = StreamingKernel(hard_limit=0.3, window_size=5, window_threshold=0.5)\n", "\n", "tokens = [\"The\", \" quantum\", \" field\", \" maintains\", \" coherence\", \" across\", \" all\", \" layers\"]\n", "scores = [0.9, 0.85, 0.82, 0.80, 0.78, 0.75, 0.73, 0.70]\n", "score_iter = iter(scores)\n", "\n", "session = kernel.stream_tokens(tokens, lambda t: next(score_iter))\n", "\n", "print(f\"Tokens processed: {session.token_count}\")\n", "print(f\"Output: {session.output}\")\n", "print(f\"Avg coherence: {session.avg_coherence:.3f}\")\n", "print(f\"Min coherence: {session.min_coherence:.3f}\")\n", "print(f\"Halted: {session.halted}\")"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Hard Limit Halt\n", "Watch the kernel halt when coherence drops below threshold."]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["kernel2 = StreamingKernel(hard_limit=0.5)\n", "degrading_scores = [0.9, 0.7, 0.6, 0.4, 0.3]  # 4th token triggers halt\n", "si = iter(degrading_scores)\n", "\n", "session2 = kernel2.stream_tokens([\"a\", \"b\", \"c\", \"d\", \"e\"], lambda t: next(si))\n", "print(f\"Halted: {session2.halted}\")\n", "print(f\"Halt reason: {session2.halt_reason}\")\n", "print(f\"Tokens before halt: {session2.halt_index}\")"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Async Streaming (for WebSocket)\n", "The `AsyncStreamingKernel` yields events as an async generator."]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import asyncio\n", "from director_ai.core.async_streaming import AsyncStreamingKernel\n", "\n", "async def demo():\n", "    kernel = AsyncStreamingKernel(hard_limit=0.3)\n", "    tokens = [\"Hello\", \" world\", \" from\", \" async\"]\n", "    events = []\n", "    async for event in kernel.stream_tokens(tokens, lambda t: 0.85):\n", "        events.append(event)\n", "        print(f\"  Token {event.index}: '{event.token}' → coherence={event.coherence:.2f}\")\n", "    print(f\"Total events: {len(events)}\")\n", "\n", "await demo()"]}
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.12.0"}},
 "nbformat": 4,
 "nbformat_minor": 5
}
